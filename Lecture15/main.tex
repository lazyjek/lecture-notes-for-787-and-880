\documentclass[11pt]{article}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{fullpage}
\usepackage{epsfig}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{theorem}
\usepackage{tabu,multirow}
\usepackage{graphicx}
\usepackage{color} 
%\usepackage{ulem}
\usepackage{floatrow}
\usepackage[labelfont=bf]{caption}
\captionsetup[table]{position=bottom,name=Figure}
\captionsetup[subtable]{textfont=it,position=top}
\usepackage{subcaption}
\usepackage{enumitem}


\makeatletter
\setlength{\textwidth}{6.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{0.25in}
\setlength{\textheight}{8.25in}
\setlength{\headheight}{0pt}
\setlength{\headsep}{0pt}
\setlength{\marginparwidth}{59pt}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
\setlength{\theorempreskipamount}{5pt plus 1pt}
\setlength{\theorempostskipamount}{0pt}
\setlength{\abovedisplayskip}{8pt plus 3pt minus 6pt}

\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                 {2ex plus -1ex minus -.2ex}%
                                 {1.3ex plus .2ex}%
                                 {\normalfont\Large\bfseries}}%
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                   {1ex plus -1ex minus -.2ex}%
                                   {1ex plus .2ex}%
                                   {\normalfont\large\bfseries}}%
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                   {1ex plus -1ex minus -.2ex}%
                                   {1ex plus .2ex}%
                                   {\normalfont\normalsize\bfseries}}
\renewcommand\paragraph{\@startsection{paragraph}{4}{0mm}%
                                  {1ex \@plus1ex \@minus.2ex}%
                                  {-1em}%
                                  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\parindent}%
                                     {2.0ex \@plus1ex \@minus .2ex}%
                                     {-1em}%
                                    {\normalfont\normalsize\bfseries}}
\makeatother

\newenvironment{proof}{{\bf Proof:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofof}[1]{{\bf Proof of #1:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofofnobox}[1]{{\bf#1:  }}{}
\newenvironment{example}{{\bf Example:  }}{\hfill\rule{2mm}{2mm}}
\renewcommand{\thesection}{\lecnum.\arabic{section}}

\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}

\newtheorem{fact}{Fact}[section]
\newtheorem{lemma}[fact]{Lemma}
\newtheorem{theorem}[fact]{Theorem}
\newtheorem{definition}[fact]{Definition}
\newtheorem{corollary}[fact]{Corollary}
\newtheorem{proposition}[fact]{Proposition}
\newtheorem{claim}[fact]{Claim}
\newtheorem{exercise}[fact]{Exercise}

% math notation
\newcommand{\R}{\ensuremath{\mathbb R}}
\newcommand{\Z}{\ensuremath{\mathbb Z}}
\newcommand{\N}{\ensuremath{\mathbb N}}
\newcommand{\F}{\ensuremath{\mathcal F}}
\newcommand{\SymGrp}{\ensuremath{\mathfrak S}}
\newcommand{\pr}{{\bf {\rm Pr}}}

\newcommand{\CCP}{\ensuremath{\sf P}}
\newcommand{\CCNP}{\ensuremath{\sf NP}}
\newcommand{\C}{\ensuremath{\mathcal C}}

\newcommand{\size}[1]{\ensuremath{\left|#1\right|}}
\newcommand{\ceil}[1]{\ensuremath{\left\lceil#1\right\rceil}}
\newcommand{\floor}[1]{\ensuremath{\left\lfloor#1\right\rfloor}}
\newcommand{\poly}{\operatorname{poly}}
\newcommand{\polylog}{\operatorname{polylog}}

% some abbreviations
\newcommand{\e}{\varepsilon}
\newcommand{\half}{\ensuremath{\frac{1}{2}}}
\newcommand{\junk}[1]{}
\newcommand{\sse}{\subseteq}
\newcommand{\union}{\cup}
\newcommand{\meet}{\wedge}

\newcommand{\prob}[1]{\ensuremath{\text{{\bf Pr}$\left[#1\right]$}}}
\newcommand{\expct}[1]{\ensuremath{\text{{\bf E}$\left[#1\right]$}}}
\newcommand{\Event}{{\mathcal E}}

\newcommand{\mnote}[1]{\normalmarginpar \marginpar{\tiny #1}}

\newcommand{\headings}[4]{
\noindent
\fbox{\parbox{\textwidth}{
{\bf CS787: Advanced Algorithms} \hfill {{\bf Scribe:} #3}\\
\vspace{0.02in}
{{\bf Lecture #1:} #2} \hfill {{\bf Date:} #4}
}}
\vspace{0.2in}
}

\newcommand{\stargraph}[2]{\begin{tikzpicture}
    \node[circle,fill=black] at (360:0mm) (center) {};
    \foreach \n in {1,...,#1}{
        \node[circle,fill=black] at ({\n*360/#1}:#2cm) (n\n) {};
        \draw (center)--(n\n);
        \node at (0,-#2*1.5) {$K_{1,#1}$}; % delete line to remove label
    }
\end{tikzpicture}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document begins here %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\newcommand{\lecnum}{15}
\headings{\lecnum}{Online Algorithm III}{Jennifer Cao,Sihan Liu}{October 24, 2019}

Last time we check investigate the online algorithms for page caching. 
\begin{itemize}
\item
For deterministic algorithm, we show that \textbf{FIFO(First In First Out)} and \textbf{LRU(Least Recently Used} are \textbf{k-competitive} and the bound is tight for any deterministic algorithm.
\item
For the randomized setting, we show that \textbf{Marking Algorithm} has achieved competitive ratio of $\boldsymbol{\log k}$.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Paging Problem
% 1. Definition
% 2. Deterministic Algorithms
% 3. k-competitive
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{$\boldsymbol{\log k}$ is tight for any randomized paging algorithm}
It is hard to construct a deterministic adversarial setting directly due to the randomness. Instead, we formulate the problem in a game theoretical manner where the problem essentially becomes a min-max game between algorithm designer and the sequence constructor.
\subsection{Yao's Min-max Principle}
Let $\alpha$ be one specific decision instance made by the algorithm and $A$ be the set of all possible instances. \newline

Let $\sigma$ be the one specific sequence instance and $\Sigma$ be the set of all possible sequence instances. \newline

Denote $\Delta(\cdot)$ as the mixture operator.\newline

Denote $cost(\alpha, \sigma)$ as the cost by applying decisions $\alpha$ to the input $\sigma$.\newline

The game is essentially:
$$
\min_{\alpha \sim \Delta(\uprightcal{A})}\max_{\sigma \sim \Delta(\Sigma)}\mathbb{E}\left[\frac{cost(\alpha, \sigma)}{cost(OPT, \sigma)}\right]
$$

Applying the min-max theorem, we can reduce it to:
\begin{align*}
&\min_{\alpha \sim \Delta(\uprightcal{A})}\max_{\sigma \sim \Delta(\Sigma)}\mathbb{E}\left[\frac{cost(\alpha, \sigma)}{cost(OPT, \sigma)}\right] \\
&=\max_{\sigma \sim \Delta(\Sigma)}\min_{\alpha \sim \Delta(\uprightcal{A})}\mathbb{E}\left[\frac{cost(\alpha, \sigma)}{cost(OPT, \sigma)}\right] \\
&\geq \min_{\alpha \sim A} \mathbb{E}\left[\frac{cost(\alpha, \sigma)}{cost(OPT, \sigma)}\right], \forall \sigma \sim \Delta(\Sigma) \\
&\text{(notice that we have got rid of the randomness in our decisions)}
\end{align*}
\newpage
\begin{theorem}
    Any randomized online algorithm cannot do better than $\boldsymbol{\Omega(\log k)}$
\end{theorem}
Our sequence only picks from page $1, \dots, k, k+1$, where $k$ is the cache capacity. At every time, it picks a random page uniformly from the options. Then, it can easily be shown that regardless of what decisions the algorithm has made, its expected cost over $T$ steps will be: $\mathbb{E}\left[cost(\alpha, \sigma)\right] = \frac{T}{k+1}$ as a cache miss occurs w.p $P = \frac{1}{k+1}$. \newline 

Next, define \textbf{phase} as the shortest sub-sequence where all $(k+1)$ pages has appeared for at least once. The O.P.T will make exactly 1 cache miss during one phase. Therefore, for a phase $\sigma_p$ of length $T$, it can be shown that:
$\mathbb{E}\left[cost(OPT, \sigma_p)\right] = \frac{T}{\mathbb{E}\left[\text{length of the phase}\right]}$

Calculating the length of a phase is exactly the standard coupon collector problem. \newline

With probability 1, we will see the first new page at the start of the sequence.\newline

Assume that we have already seen $l$ pages, then the probability that the next page is a unseen new page will be $P = \frac{k+1-l}{k+1}$. \newline

Thus, we have:
\begin{align*}
\mathbb{E}\left[\text{length of a phase}\right] &= 1 + \frac{k+1}{k} + \frac{k+1}{k-1} + \cdots  + k+1\\
&= (k+1) \cdot H_{k+1}, \text{where $H_{k+1}$ is the $(k+1)_{th}$ harmonic series}    
\end{align*}

In summary, we have:
\begin{align*}
    &cost(OPT) = \frac{T}{(k+1) \cdot H_{k+1}}\\
    &cost(Algo) = \frac{T}{(k+1)}
\end{align*}

Thus, any randomized cannot do better than $\Omega{H_{k+1}} \approx \Omega(\log k)$ competitive ratio under the given random sequence. 
\section{K-Server Problem}
Initially, we have k-servers scattered around a metric space. A sequence of requests happen and we need to send a server to handle each response. The objective is to minimize the total distance traveled by the servers.
\newpage
\subsection{K-Server Problem captures the paging problem}
For a cache with capacity $k$, we define a star graph with $k+2$ vertices:
\begin{center}
    \stargraph{7}{2} 
    % usage: \stargraph{number of radial nodes>0}{radius in cm}
\end{center}
Our servers scatter on the corner vertices. Every time, a response happen at one of the corner vertices. If a request happens at one of the vertex without a server, another server has to move to the vertex with a cost of 2 and the process thereby corresponds to a cache miss.
\subsection{Competitive Online Algorithm for k-server}
We focus on the strategy when the metric space is a 1-d straight line though it can be generalized to any arbitrary metric space.
\begin{algorithm}
\caption{Move servers in response to request}
\begin{algorithmic} 
\IF{\text{Requests happen outside the interval covered by the servers}}
\text{Move the closest server to handle the event}
\ELSE
\text{Move both the server on the left side and right side of the request until the first one arrives}
\ENDIF
\end{algorithmic}
\end{algorithm}
\newline
To help us conduct the competitive analysis, we define the following auxiliary potential function:
$$
\varphi = k \cdot (\text{min cost match between server positions by Algo and OPT}) + (\text{pair-wise distances of servers in Algo})
$$
Make the following notation
\begin{itemize}
    \item  $M = (\text{min cost match between server positions by Algo and OPT})$.
    \item  $S = (\text{pair-wise distances of servers in Algo})$.
\end{itemize}



Next, we consider how moves from the Optimal algorithm and our algorithm will influence the potential function. For convenience of analysis, we assume the optimal algorithm moves first, and our algorithm moves after in response to a request. \newline

\begin{lemma}
For two different server arrangements $X_{OPT}$ and $X_{{Algo}}$, we can always first sort $X_{OPT}$ and $X_{Algo}$ on the line and then match them by order to obtain a min cost matching.
\end{lemma}

The lemma is useful when arguing for the change $\Delta{M}$.

Suppose O.P.T moves by $d$:
\begin{itemize}
    \item $\Delta{M} \leq d$ since our algorithm has not moved yet and thus the original match immediately gives $\Delta{M} = d$. The optimal match will only have smaller cost. Thus, we must have $\Delta{M} \leq d$.
    \item $\Delta{S} = 0$ since our algorithm has never moved.
\end{itemize}

Suppose our algorithm moves by $d$: \newline
If the request is outside the range, we have: \newline
\begin{itemize}
    \item $\Delta{M} = -d$, as the server moved by our algorithm gets closer to the rightmost server of the O.P.T for exactly $d$.
    \item $\Delta{S} = (k-1)d$, as rightmost server of our algorithm is getting further away from all the other servers.
\end{itemize}
If the request is within the interval of servers $L$ and $R$,
\begin{itemize}
    \item $\Delta{M} <= 0$. By our lemma, there could be at two types of min-cost matching before our algorithm moves. 
    \begin{itemize}
        \item Both $L$ and $R$ get matched to some servers located on the left of the request (inclusive). Then $R$ gets closer to its original matching partner for exactly $d$ units and $L$ gets further from its partner for at most $d$ units.
        \item Both $L$ and $R$ get matched to some servers located on the right of the request (inclusive). Then $L$ gets closer to its original matching partner for exactly $d$ units and $R$ gets further from its partner for at most $d$ units.
    \end{itemize}
    \item $\Delta{S} = -2d$ as the two servers are moving towards each other and their distance to other servers cancel out exactly.
\end{itemize} \newline


In summary, we must have $\Delta{\varphi}_i \leq k \Delta{Cost(OPT)}_i - \Delta{Cost(Algo)}_i$, where $\Delta{Cost(OPT)}_i$ and $\Delta{Cost(Algo)}_i$ is the distance moved by O.P.T and by our algorithm accordingly in response to request $i$. \newline 

Summing it over all the steps/requests from $1, \cdots, i$, we then have: \newline
$\varphi_i \leq k \cdot Cost(OPT)_i + Cost(Algo)_i$, where $Cost(OPT)_i$ and $Cost(Algo)_i$ are the cumulative distance/cost moved by O.P.T and our algorithm accordingly up to request $i$. \newline 

Since $\varph_i \geq 0$, we thus have $ k \cdot Cost(OPT)_i \leq Cost(Algo)_i$. \newline

Therefore, our algorithm is k-competitive. 
\end{document}